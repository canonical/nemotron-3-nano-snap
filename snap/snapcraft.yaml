name: nemotron-3-nano
base: core24
summary: Inference Snap for Nemotron 3 nano
description: |
  This is an inference snap that lets you run Nemotron 3 nano.

adopt-info: version

grade: devel
confinement: strict
compression: lzo

environment:
  SNAP_COMPONENTS: /snap/$SNAP_INSTANCE_NAME/components/$SNAP_REVISION
  ARCH_TRIPLET: $CRAFT_ARCH_TRIPLET_BUILD_FOR
  OCL_ICD_VENDORS: $SNAP/etc/OpenCL/vendors

layout:
  # OpenCL looks in /etc/OpenCL/vendors for .icd files containing the paths to shared objects
  /etc/OpenCL/vendors:
    bind: $SNAP/etc/OpenCL/vendors
  # Intel icd files use an absolute path to Intel OpenCL shared objects. Use a layout to mount the so files at the expected location
  /usr/lib/$CRAFT_ARCH_TRIPLET_BUILD_FOR/intel-opencl:
    bind: $SNAP/usr/lib/$CRAFT_ARCH_TRIPLET_BUILD_FOR/intel-opencl

plugs:
  # To allow side-loading models into server (root daemon) from user home directory
  home:
    read: all

hooks:
  install:
    plugs:
      - hardware-observe
      - opengl

parts:
  version:
    plugin: dump
    source: .
    build-packages:
      - git-lfs
    override-pull: |
      craftctl set version="v3+$(git -C $SNAPCRAFT_PROJECT_DIR describe --always)"

  cli:
    source: https://github.com/canonical/inference-snaps-cli.git
    source-tag: v1.0.0-beta.28
    plugin: go
    build-snaps:
      - go/1.24/stable
    stage-packages:
      - pciutils
      - nvidia-utils-580 # for Nvidia vRAM and Cuda Capability detection
      - clinfo
    override-build: |
      craftctl default

      # For tab completion
      ln --symbolic ./modelctl $CRAFT_PART_INSTALL/bin/nemotron-3-nano
    organize:
      bin/cli: bin/modelctl

    prime:
      # Exclude nvidia icd to avoid clinfo from looking up properties for nvidia GPUs.
      # See: https://github.com/canonical/inference-snaps/issues/148
      - -etc/OpenCL/vendors/nvidia.icd
        
  engines:
    source: engines
    plugin: dump
    organize:
      "*": engines/
  
  scripts:
    source: scripts
    plugin: dump
    organize:
      "*": bin/

  common-runtime-dependencies:
    plugin: nil
    stage-snaps:
      - jq

  model-30b-a3b-q4-k-m-gguf:
    plugin: nil
    override-prime: |
      set +x # reduce noise

      # Bypassing the usual part lifecycle saves disk space and time when dealing with large files
      # Copy model files directly from the project into the respective component's prime directory
      for i in {1..6}; do
        source="$CRAFT_PROJECT_DIR/components/model-30b-a3b-q4-k-m-gguf/Nemotron-Nano-3-30B-A3B-Q4_K_M-0000${i}-of-00006.gguf"
        target="CRAFT_COMPONENT_MODEL_30B_A3B_Q4_K_M_GGUF_${i}_OF_6_PRIME"

        cp -v "$source" "${!target}/"

        if [ "$i" -eq 1 ]; then
          # Copy any other non-gguf files from the components directory
          for f in "$CRAFT_PROJECT_DIR/components/model-30b-a3b-q4-k-m-gguf"/*; do
            if [ -f "$f" ]; then
              case "$f" in
                *.gguf) ;;
                *) cp -v "$f" "${!target}/" ;;
              esac
            fi
          done
        else
          # Each component must include a component.yaml config file.
          # For components other than the first, create an empty one:
          echo "# No config" > "${!target}/component.yaml"
        fi
      done

  llama-cpp:
    plugin: dump
    source: 
      - on amd64: https://github.com/jpm-canonical/llama.cpp-builds/releases/download/b7731/llamacpp-amd64.tar.gz
      - on arm64: https://github.com/jpm-canonical/llama.cpp-builds/releases/download/b7731/llamacpp-arm64.tar.gz
    override-build: |
      # Move license files to be included in the snap, not the component
      mkdir -p $CRAFT_PRIME/usr/share/doc/
      mv licenses $CRAFT_PRIME/usr/share/doc/llama.cpp

      craftctl default
    stage-packages:
      - libgomp1
    organize:
      "*": (component/llama-cpp)
  
  llama-cpp-local-files:
    plugin: dump
    source: components/llama-cpp
    organize:
      "*": (component/llama-cpp)
    
  llama-cpp-cuda:
    plugin: dump
    source: 
      - on amd64: https://github.com/jpm-canonical/llama.cpp-builds/releases/download/b7731/llamacpp-amd64+cuda12.tar.gz
      - on arm64: https://github.com/jpm-canonical/llama.cpp-builds/releases/download/b7731/llamacpp-arm64+cuda12.tar.gz
    override-build: |
      # Move license files to be included in the snap, not the component
      mkdir -p $CRAFT_PRIME/usr/share/doc/
      mv licenses $CRAFT_PRIME/usr/share/doc/llama.cpp-cuda

      craftctl default
    stage-packages:
      - libgomp1
    organize:
      "*": (component/llama-cpp-cuda)

  llama-cpp-cuda-local-files:
    plugin: dump
    source: components/llama-cpp-cuda
    organize:
      "*": (component/llama-cpp-cuda)

  notice:
    plugin: nil
    source: NOTICE
    source-type: file
    override-build: |
      license_dir=$CRAFT_PART_INSTALL/usr/share/doc
      mkdir -p $license_dir
      cp NOTICE $license_dir/
      # Add license files referenced in NOTICE
      cp $SNAPCRAFT_PROJECT_DIR/LICENSE $license_dir/
      cp $SNAPCRAFT_PROJECT_DIR/nvidia-open-model-license-agreements-24-10-2025.pdf $license_dir/

components:
  model-30b-a3b-q4-k-m-gguf-1-of-6: &model
    type: standard
    summary: NVIDIA Nemotron-Nano-3-30B-A3B-Q4_K_M GGUF
    description: Model weights for NVIDIA Nemotron 3 Nano with 30B (3.5B active) parameters in GGUF format

  model-30b-a3b-q4-k-m-gguf-2-of-6:
    <<: *model

  model-30b-a3b-q4-k-m-gguf-3-of-6:
    <<: *model

  model-30b-a3b-q4-k-m-gguf-4-of-6:
    <<: *model

  model-30b-a3b-q4-k-m-gguf-5-of-6:
    <<: *model

  model-30b-a3b-q4-k-m-gguf-6-of-6:
    <<: *model

  llama-cpp:
    type: standard
    summary: llama.cpp using default CPU instruction sets
    description: LLM inference in C/C++
  
  llama-cpp-cuda:
    type: standard
    summary: llama.cpp with CUDA backend
    description: LLM inference in C/C++

apps:
  nemotron-3-nano:
    command: bin/nemotron-3-nano
    completer: bin/completion.bash
    plugs:
      - hardware-observe
      - opengl
      - network

  server:
    command: bin/server.sh
    daemon: simple
    plugs:
      - network-bind
      - hardware-observe
      - opengl
      - home

